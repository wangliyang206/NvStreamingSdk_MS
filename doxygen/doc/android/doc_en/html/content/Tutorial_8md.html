<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.17"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>MeiCam SDK For Android: Detailed Development Guidance</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">MeiCam SDK For Android
   &#160;<span id="projectnumber">3.13.2</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.17 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">Detailed Development Guidance </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><ul>
<li>1 <a class="el" href="Tutorial_8md.html#Overview">Overview</a><ul>
<li>1.1 <a class="el" href="Tutorial_8md.html#Supported">Formats 1.1 Supported Formats</a> Formats "Supported Formats"</li>
<li>1.2 <a class="el" href="Tutorial_8md.html#Precautions">Precautions</a><ul>
<li>1.2.1 <a class="el" href="Tutorial_8md.html#Limitations">Limitations</a></li>
<li>1.2.2 <a class="el" href="Tutorial_8md.html#Running">environment 1.2.2 Running environment</a> environment "Running environment"</li>
<li>1.2.3 <a class="el" href="Tutorial_8md.html#Important_tips">Important tips</a></li>
</ul>
</li>
</ul>
</li>
<li>2 <a class="el" href="Tutorial_8md.html#Quick_start">Quick start</a><ul>
<li>2.1 <a class="el" href="Tutorial_8md.html#Import_library">Import library</a></li>
</ul>
</li>
<li>3 <a class="el" href="Tutorial_8md.html#Instructions">for usage 3 Instructions for usage</a> for usage "Instructions for usage"<ul>
<li>3.1 <a class="el" href="Tutorial_8md.html#Recording">Recording</a><ul>
<li>3.1.1 <a class="el" href="Tutorial_8md.html#Derived">from the CaptureDeviceCallback interface 3.1.1 Derived from the CaptureDeviceCallback interface</a> from the CaptureDeviceCallback interface "Derived from the CaptureDeviceCallback interface"</li>
<li>3.1.2 <a class="el" href="Tutorial_8md.html#The">class of NvsStreamingContext 3.1.2 The class of NvsStreamingContext</a> class of NvsStreamingContext "The class of NvsStreamingContext"</li>
<li>3.1.3 <a class="el" href="Tutorial_8md.html#The">class of NvsStreamingContext 3.1.2 The class of NvsStreamingContext</a> preview class of NvsLiveWindow "The preview class of NvsLiveWindow"</li>
<li>3.1.4 <a class="el" href="Tutorial_8md.html#Preparation">before previewing 3.1.4 Preparation before previewing</a> before previewing "Preparation before previewing"</li>
<li>3.1.5 <a class="el" href="Tutorial_8md.html#Starting">preview 3.1.5 Starting preview</a> preview "Starting preview"<ul>
<li>3.1.5.1 <a class="el" href="Tutorial_8md.html#Recording">3.1 Recording</a> With beauty and without beauty "Recording With beauty and without beauty"</li>
</ul>
</li>
<li>3.1.6 <a class="el" href="Tutorial_8md.html#Recording">3.1 Recording</a> and stop recording "Recording and stop recording"</li>
<li>3.1.7 <a class="el" href="Tutorial_8md.html#Recording">3.1 Recording</a> parameter adjustment "Recording parameter adjustment"</li>
<li>3.1.8 <a class="el" href="Tutorial_8md.html#Beauty">Beauty</a></li>
<li>3.1.9 <a class="el" href="Tutorial_8md.html#Special">effects with recording 3.1.9 Special effects with recording</a> effects with recording "Special effects with recording"<ul>
<li>3.1.9.1 <a class="el" href="Tutorial_8md.html#Built-in">effects for recording 3.1.9.1 Built-in effects for recording</a> effects for recording "Built-in effects for recording"</li>
<li>3.1.9.2 <a class="el" href="Tutorial_8md.html#Extended">package effects for recording 3.1.9.2 Extended package effects for recording</a> package effects for recording "Extended package effects for recording"</li>
</ul>
</li>
</ul>
</li>
<li>3.2 <a class="el" href="Tutorial_8md.html#Editing">Editing</a><ul>
<li>3.2.1 <a class="el" href="Tutorial_8md.html#Create">the timeline and set the video resolution 3.2.1 Create the timeline and set the video resolution</a> the timeline and set the video resolution "Create the timeline and set the video resolution"</li>
<li>3.2.2 <a class="el" href="Tutorial_8md.html#Hybrid">editing for the multi-segment video and image 3.2.2 Hybrid editing for the multi-segment video and image</a> editing for the multi-segment video and image "Hybrid editing for the multi-segment video and image"</li>
<li>3.2.3 <a class="el" href="Tutorial_8md.html#Playback">and seeking 3.2.3 Playback and seeking</a> and seeking "Playback and seeking"</li>
<li>3.2.4 <a class="el" href="Tutorial_8md.html#Video">triming 3.2.4 Video triming</a> triming "Video triming"</li>
<li>3.2.5 <a class="el" href="Tutorial_8md.html#Remove">the clip on the track 3.2.5 Remove the clip on the track</a> the clip on the track "Remove the clip on the track"</li>
<li>3.2.6 <a class="el" href="Tutorial_8md.html#Sorting">of the video clip 3.2.6 Sorting of the video clip</a> of the video clip "Sorting of the video clip"</li>
<li>3.2.7 <a class="el" href="Tutorial_8md.html#Define">the duration for image 3.2.7 Define the duration for image</a> the duration for image "Define the duration for image"</li>
<li>3.2.8 <a class="el" href="Tutorial_8md.html#Remove">the clip on the track 3.2.5 Remove the clip on the track</a> the timeline and track "Remove the timeline and track"</li>
</ul>
</li>
<li>3.3 <a class="el" href="Tutorial_8md.html#Audio">implementation 3.3 Audio implementation</a> implementation "Audio implementation"<ul>
<li>3.3.1 <a class="el" href="Tutorial_8md.html#Add">Add</a> music "Add music"</li>
<li>3.3.2 <a class="el" href="Tutorial_8md.html#Music">triming 3.3.2 Music triming</a> triming "Music triming"</li>
</ul>
</li>
<li>3.4 <a class="el" href="Tutorial_8md.html#Caption">Caption</a><ul>
<li>3.4.1 <a class="el" href="Tutorial_8md.html#Add">Add</a> and remove caption "Add and remove caption"</li>
<li>3.4.2 <a class="el" href="Tutorial_8md.html#Get">the caption from timeline 3.4.2 Get the caption from timeline</a> the caption from timeline "Get the caption from timeline"</li>
<li>3.4.3 <a class="el" href="Tutorial_8md.html#Modify">properties of caption 3.4.3 Modify properties of caption</a> properties of caption "Modify properties of caption"</li>
<li>3.4.4 <a class="el" href="Tutorial_8md.html#Modify">properties of caption 3.4.3 Modify properties of caption</a> the in and out point of caption "Modify the in and out point of caption"</li>
</ul>
</li>
<li>3.5 <a class="el" href="Tutorial_8md.html#Animated">sticker 3.5 Animated sticker</a> sticker "Animated sticker"<ul>
<li>3.5.1 <a class="el" href="Tutorial_8md.html#Add">Add</a> and remove animated sticker "Add and remove animated sticker"<ul>
<li>3.5.2 <a class="el" href="Tutorial_8md.html#Get">the caption from timeline 3.4.2 Get the caption from timeline</a> the animated stickers from timeline "Get the animated stickers from timeline"</li>
<li>3.5.3 <a class="el" href="Tutorial_8md.html#Modify">properties of caption 3.4.3 Modify properties of caption</a> the properties of animated sticker "Modify the properties of animated sticker"</li>
<li>3.5.4 <a class="el" href="Tutorial_8md.html#Modify">properties of caption 3.4.3 Modify properties of caption</a> the in and out point of the animated sticker "Modify the in and out point of the animated sticker"</li>
</ul>
</li>
</ul>
</li>
<li>3.6 <a class="el" href="Tutorial_8md.html#Theme">Theme</a><ul>
<li>3.6.1 <a class="el" href="Tutorial_8md.html#Add">Add</a> and remove theme "Add and remove theme"</li>
<li>3.6.2 <a class="el" href="Tutorial_8md.html#Get">the caption from timeline 3.4.2 Get the caption from timeline</a> theme from the timeline "Get theme from the timeline"</li>
<li>3.6.3 <a class="el" href="Tutorial_8md.html#Modify">properties of caption 3.4.3 Modify properties of caption</a> properties of a theme "Modify properties of a theme"</li>
</ul>
</li>
<li>3.7 <a class="el" href="Tutorial_8md.html#Transition">Transition</a></li>
<li>3.8 <a class="el" href="Tutorial_8md.html#Special">effects with recording 3.1.9 Special effects with recording</a> effects "Special effects"<ul>
<li>3.8.1 <a class="el" href="Tutorial_8md.html#Video">triming 3.2.4 Video triming</a> effects "Video effects"</li>
<li>3.8.2 <a class="el" href="Tutorial_8md.html#Audio">implementation 3.3 Audio implementation</a> effects "Audio effects"</li>
<li>3.8.3 <a class="el" href="Tutorial_8md.html#Timeline">Timeline</a> video effects "Timeline video effects"<ul>
<li>3.8.3.1 <a class="el" href="Tutorial_8md.html#Add">Add</a> and remove the effects of timeline "Add and remove the effects of timeline"</li>
<li>3.8.3.2 <a class="el" href="Tutorial_8md.html#Get">the caption from timeline 3.4.2 Get the caption from timeline</a> the effects of timeline "Get the effects of timeline"</li>
<li>3.8.3.3 <a class="el" href="Tutorial_8md.html#Modify">properties of caption 3.4.3 Modify properties of caption</a> the in and out point of the effect for timeline "Modify the in and out point of the effect for timeline"</li>
</ul>
</li>
</ul>
</li>
<li>3.9 <a class="el" href="Tutorial_8md.html#Compiling">Compiling</a></li>
<li>3.10 <a class="el" href="Tutorial_8md.html#Asset">package management 3.10 Asset package management</a> package management "Asset package management"</li>
<li>3.11 <a class="el" href="Tutorial_8md.html#Callback">Callback</a></li>
</ul>
</li>
<li>4 <a class="el" href="Tutorial_8md.html#Appendix">Appendix</a></li>
</ul>
<hr  />
 <h1><a class="anchor" id="Details"></a>
Details</h1>
<h2><a class="anchor" id="Overview"></a>
1 Overview</h2>
<p>Meishe SDK is dedicated to solve the technical threshold of mobile video development. It helps users quickly including the programmers which have only andriod interface development experience to develop the video recording and editing functions with excellent performance and rich rendering effects. Meishe SDK provides the following functionalities:</p><ul>
<li>No limitation for recording and editing</li>
<li>The best beauty effect at highest standard</li>
<li>Realtime preview of triming and changing speed without transcoding</li>
<li>Hybrid editing for the video and image</li>
<li>Compiling video at different resolution up to 1080p</li>
<li>Rich transitions, filters, caption styles</li>
<li>Self-defined video theme</li>
<li>Support 4K video editing and compilation on the timeline</li>
<li>Opened custom sticker feature </li>
</ul>
<h2><a class="anchor" id="Supported"></a>
Formats 1.1 Supported Formats</h2>
<ul>
<li>Input format:<ul>
<li>Video format: MP4,MOV,WMV,M2V,MPG</li>
<li>Audio format: MP3,FLAC,AAC,M4A</li>
<li>Image format: JPG,PNG</li>
<li>Video encoding: H264,WMV,MPEG4</li>
<li>Audio encoding: MP3,AAC,PCM,FLAC</li>
</ul>
</li>
<li>Output format:<ul>
<li>Video format: MP4,MOV</li>
<li>Video encoding: H264</li>
<li>Audio coding: AAC</li>
</ul>
</li>
<li>Extended asset package (the expansion asset package holds all type of contents, including theme, caption style, filter, sticker, etc.):<ul>
<li>Theme: .theme</li>
<li>Caption: .captionstyle</li>
<li>Filter: .videofx</li>
<li>Sticker: .animatedsticker</li>
<li>Transition: .videotransition</li>
<li>Face prop：.arscene </li>
</ul>
</li>
</ul>
<h2><a class="anchor" id="Precautions"></a>
1.2 Precautions</h2>
<h2><a class="anchor" id="Limitations"></a>
1.2.1 Limitations</h2>
<p>All MeiShe SDK APIs should be called within UI thread, otherwise unforeseen errors may occur in application. Only exception is the getFrameAtTime() from the class of NvsVideoFrameRetriever. </p>
<h2><a class="anchor" id="Running"></a>
environment 1.2.2 Running environment</h2>
<p>The operating environment is as follows: android studio (required), android4.4 or later. </p>
<h2><a class="anchor" id="Important_tips"></a>
1.2.3 Important hint</h2>
<p>Currently, Meishe SDK Android version supports armeabi-v7a and arm64 instruction set packages.</p>
<p>Add in the gradle command line when using</p>
<blockquote class="doxtable">
<p>defaultConfig { </p>
</blockquote>
<blockquote class="doxtable">
<p>&emsp;&emsp;ndk { </p>
</blockquote>
<blockquote class="doxtable">
<p>&emsp;&emsp;&emsp;&emsp;abiFilters "armeabi-v7a",”arm64-v8a” </p>
</blockquote>
<blockquote class="doxtable">
<p>&emsp;&emsp;} </p>
</blockquote>
<blockquote class="doxtable">
<p>} </p>
</blockquote>
<p>Finally, how to check if the program contains the .so package? The easiest way is to use a decompression tool to modify the apk suffix to .zip, and then check whether the libs folder contains the .so package.</p>
<h2><a class="anchor" id="Quick_start"></a>
2 Quick access</h2>
<h2><a class="anchor" id="Import_library"></a>
2.1 Import library file</h2>
<p>If there is no Meishe SDK library, please download the latest SDK access version from Meishe official website: <a href="https://www.meishesdk.com/downloads">https://www.meishesdk.com/downloads</a>. There are two ways to import library files:</p>
<p>Method 1: copy directly.</p>
<p>After creating the project, copy the jar package in the NvStreamingSdk_Android_***_***\lib\android_jar path to the libs path of the project. At the same time, create two folders, armeabi-v7 and arm64-v8a, under the jniLibs folder of the project (create a folder with the same name if not).Copy all the .so files in NvStreamingSdk_Android_***_***\lib\android_armv7 to the armeabi-v7a folder created earlier, and similarly copy the contents of the android_arm64 folder to the arm64-v8a folder.</p>
<div class="image">
<img src="f51a5a9e28941ad8ea04e40808d8b430.png" alt=""/>
</div>
   <p>Method 2: Import the library by configuring the gradle command line.</p>
<p>The samples of Meishe SDK import library files through configuration command line.</p>
<div class="image">
<img src="3171c4ee2afc59adf2b292a5112ff9f3.png" alt=""/>
</div>
   <div class="image">
<img src="ccad4d50c3a551240be91d17d14dd85c.png" alt=""/>
</div>
   <h2><a class="anchor" id="Instructions"></a>
for usage 3 Instructions for usage</h2>
<h2><a class="anchor" id="Recording"></a>
3.1 Recording</h2>
<p>For recording, the API applied is in the NvsStreamingContext class,including startCapturePreview() which start capturing preview, startRecording() which start recording, and appendBuiltinCaptureVideoFx() which applies Special effects the video capture. Remark: all classes in Meishe SDK starts with "Nvs". <br  />
Please pay attention to the following two points when recording video:</p><ul>
<li>Breakpoint recording: The way the Meishe SDK implements breakpoint recording is achieved by a loop call to start recording (startRecording()) and stop recording (stopRecording()). The disadvantage is that the recording produces multiple files, and the user needs to maintain and delete the video data himself. And you need to generate a complete new file from the files which were recorded by the breakpoint through subsequent editing operations. The advantage is that various transition effects can be added between independent files, which avoids the hard switching of the video picture caused by the conversion scene.</li>
<li>Recording with effects and without effects: With effect recording which is the effect of the recorded file is the effect of the preview. Recording without effect is to use a filter or to record a 1:1 video when previewing, but the recorded file is the original 16:9 or 9:16 video without a filter. When editing the video files, users need to add the filter and trim them to 1:1. After editing and compiling,The video you get will be exactly the same as the preview video.</li>
</ul>
<p>If you want to see the specific function implementation of video recording, it is recommended to refer to the video capture module of SdkDemo. Note: Only the .mov and .mp4 files are supported for video recording and video compiling. </p>
<h2><a class="anchor" id="Derived"></a>
from the CaptureDeviceCallback interface 3.1.1 Derived from the CaptureDeviceCallback interface</h2>
<p>Before recording, the recorded Activity needs to implement the CaptureDeviceCallback interface of the NvsStreamingContext class and rewrite all the methods in the interface. The implementation code is as follows: </p><pre class="fragment">        public class MainActivity extends AppCompatActivity implements NvsStreamingContext.CaptureDeviceCallback {
                            //Please rewrite all methods by yourself
        }
</pre><h2><a class="anchor" id="The"></a>
class of NvsStreamingContext 3.1.2 The class of NvsStreamingContext</h2>
<p>NvsStreamingContext is the streaming context class of the Meishe SDK, which can be regarded as the entrance to the entire SDK framework. When you start using the Meishe SDK, you need to initialize the NvsStreamingContext class first, and then Get the NvsStreamingContext object and use it elsewhere. NvsStreamingContext is a singleton class,please destroy the NvsStreamingContext class object when use the Meishe SDK no longer or the program exit. Please make sure that don't destroy the NvsStreamingContext object in the middle. The second parameter of init() in the NvsStreamingContext class is the path of the authorization file. If there is no authorization file, the empty string is given. <br  />
 The codes of NvsStreamingContext initialization are as follow:： </p><pre class="fragment">                    @Override
                    protected void onCreate(Bundle savedInstanceState) {
                            super.onCreate(savedInstanceState);
                            m_streamingContext = NvsStreamingContext.init(this, null);//初始化Streaming Context
                            setContentView(R.layout.activity_main);
                    }
</pre><p>Destroy the NvsStreamingContext object: </p><pre class="fragment">                    @Override
                    protected void onDestroy() {
                            //Destroy the streamingContext object
                            m_streamingContext = null;
                            NvsStreamingContext.close();
                    }
</pre><h2><a class="anchor" id="The"></a>
class of NvsStreamingContext 3.1.2 The class of NvsStreamingContext</h2>
<p>The NvsLiveWindow control is required to use in the xml file of the recording interface that is used to preview when recording or editing. The xml file is set as follows: </p><pre class="fragment">                    &lt;com.meicam.sdk.NvsLiveWindow
                            android:layout_height="match_parent"
                            android:id="@+id/liveWindow"
                            android:layout_width="match_parent"
                    /&gt;
</pre><p>The aspect ratio of NvsLiveWindow should be 1:1, 4:3, 16:9, 9:16, etc. It is best to match the parameter of "aspectRatio" for the API of startCapturePreview:videoResGrade:flags:aspectRatio:. Otherwise, the previewed image is the image which trims the video that has finished recording. <br  />
NvsLiveWindow fill mode: </p><pre class="fragment">                    public class NvsLiveWindow extends SurfaceView implements SurfaceHolder.Callback
                    {
                            //The image is evenly filled and trimed if necessary (default mode)
                            public static final int FILLMODE_PRESERVEASPECTCROP = 0;

                            //The image is evenly scaled to fit the window, no triming
                            public static final int FILLMODE_PRESERVEASPECTFIT = 1;

                            //The image is scaled to fit the window
                            public static final int FILLMODE_STRETCH = 2;
                    }
</pre><p>For the three fill modes, images are shown as below:：</p><ul>
<li>The mode of FILLMODE_PRESERVEASPECTCROP: <div class="image">
<img src="PreserveAspectCrop.png" alt=""/>
</div>
   </li>
<li>The mode of FILLMODE_PRESERVEASPECTFIT: <div class="image">
<img src="PreserveAspectFit.png" alt=""/>
</div>
   </li>
<li>The mode of FILLMODE_STRETCH: <div class="image">
<img src="Stretch.png" alt=""/>
</div>
   </li>
</ul>
<p>Another way of previewing is to connect to SurfaceTexture and preview on SurfaceView. The interface is as follows: </p><pre class="fragment">                    //Connect the timeline to a SurfaceTexture object, the rendering results of the timeline will be output to the SurfaceTexture object.
        public boolean connectTimelineWithSurfaceTexture(NvsTimeline timeline, SurfaceTexture outputSurfaceTexture)

                    //Connect the timeline to a SurfaceTexture object and set the proxy level. The rendering result of the timeline will be output to the SurfaceTexture object.
        public boolean connectTimelineWithSurfaceTexture(NvsTimeline timeline, SurfaceTexture outputSurfaceTexture, NvsRational proxyScale)
</pre><h2><a class="anchor" id="Preparation"></a>
before previewing 3.1.4 Preparation before previewing</h2>
<pre class="fragment">                    //Set the Callback for NvsStreamingContext (Users must set!!!).
        m_streamingContext.setCaptureDeviceCallback(this);
        if (m_streamingContext.getCaptureDeviceCount() == 0)
            return;
                    //Connect the capture preview to the NvsLiveWindow control(Users must set!!!).
        if (!m_streamingContext.connectCapturePreviewWithLiveWindow(m_liveWindow)) {
            Log.e(TAG, "Failed to connect capture preview with livewindow!");
            return;
        }
                    //Determine that the count of acquisition devices.
                    //If the count of the acquisition device is 1, the front camera cannot be turned on.
        if (m_streamingContext.getCaptureDeviceCount() &gt; 1)
            m_switchBackFacing.setEnabled(true);

                    //Determine if it's a back face device
                    if (m_streamingContext.isCaptureDeviceBackFacing(0))
        {
            .....
        }
</pre><h2><a class="anchor" id="Starting"></a>
preview 3.1.5 Starting preview</h2>
<p>The capture preview of video is required before users start recording video.The codes are as follow: </p><pre class="fragment">                    //Start acquisition preview
                    m_aspectRatio.den = 1;
                    m_aspectRatio.num = 1;
        m_streamingContext.startCapturePreview(m_currentDeviceIndex, NvsStreamingContext.VIDEO_CAPTURE_RESOLUTION_GRADE_SUPER_HIGH, 0, m_aspectRatio);
</pre><h2><a class="anchor" id="Recording"></a>
3.1 Recording</h2>
<p>When capturing the preview, users can see the added beauty and filters on the image of previewing. If you turn on with special effects recording, the recorded file will have a beauty and filter. If not, the recorded video file has no beauty and filter effects,users can add the beauty and filters in the subsequent editing functions. With special effects recording, you must set the value which the parameter of "flags" for startCapturePreview() to NvsStreamingContext.STREAMING_ENGINE_CAPTURE_FLAG_DONT_USE_SYSTEM_RECORDER, otherwise set to 0. <br  />
For more information, please refer to: <a href="https://www.meishesdk.com/android/doc_ch/html/content/videoRecorderMode_8md.html">https://www.meishesdk.com/android/doc_ch/html/content/videoRecorderMode_8md.html</a> </p>
<h2><a class="anchor" id="Recording"></a>
3.1 Recording</h2>
<p>The output file of recording is .mov or .mp4. startRecording() turns on recording, and stopRecording() stops recording. The parameter of "outputFilePath" for startRecording() is the path to the recorded video file. m_streamingContext.startRecording(file.getAbsolutePath()); m_streamingContext.stopRecording();</p>
<h2><a class="anchor" id="Recording"></a>
3.1 Recording</h2>
<p>Set whether the flash is on: </p><pre class="fragment">                    m_streamingContext.toggleFlash(true);
</pre><p>Auto focus: </p><pre class="fragment">                    m_streamingContext.startAutoFocus(new RectF(50,50,100,100));
</pre><p>Set the exposure compensation: </p><pre class="fragment">                    m_streamingContext.setExposureCompensation(40);
</pre><p>Set value of zooming: </p><pre class="fragment">                    m_streamingContext.setZoom(0.8);
</pre><h2><a class="anchor" id="Beauty"></a>
3.1.8 Beauty</h2>
<p>After adding a beauty effect, you can see the beauty effect in the preview window. When recording a video, the user needs to choose to record with a beauty or not according to the performance of the mobile phone. Beauty effects can be set with strength, whitening, reddening, basic beauty effects, the Intensity of basic beauty effects, sharpening. For specific beauty effects, please refer to the module of "Video Capture" in the "SdkDemo". <br  />
The code is as follows: </p><pre class="fragment">                    NvsCaptureVideoFx beautyFx = m_streamingContext.appendBeautyCaptureVideoFx();//add beauty effects
                    beautyFx.setFloatVal("Strength", 0.5);//Set the value of "Strength"
                    beautyFx.setFloatVal("Whitening", 0.5);//Set the value of "Whitening"
                    beautyFx.setFloatVal("Reddening", 0.5);//Set the value of "Reddening"
                    beautyFx.setBooleanVal("Default Beauty Enabled", true);//Set the value of "Default Beauty Enabled"
                    beautyFx.setBooleanVal("Default Sharpen Enabled", true);//Set the value of "Default Sharpen Enabled"
                    beautyFx.setFloatVal("Default Intensity", 0.5);//Set the value of "Default Intensity"
</pre><h2><a class="anchor" id="Special"></a>
effects with recording 3.1.9 Special effects with recording</h2>
<p>There are two types of captured effects: built-in captured effects and extended package effects which can obtain through resource package installation. </p>
<h2><a class="anchor" id="Built-in"></a>
effects for recording 3.1.9.1 Built-in effects for recording</h2>
<p>if you want to get the name of the built-in captured effect,please refer to the list: <a href="https://www.meishesdk.com/android/doc_ch/html/content/FxNameList_8md.html">https://www.meishesdk.com/android/doc_ch/html/content/FxNameList_8md.html</a>。 <br  />
Add and remove effects: </p><pre class="fragment">        m_streamingContext.appendBuiltinCaptureVideoFx(fxName);
        m_streamingContext.removeAllCaptureVideoFx();
</pre><h2><a class="anchor" id="Extended"></a>
package effects for recording 3.1.9.2 Extended package effects for recording</h2>
<p>When using the extended package effect, users need to install firstly the resource package and get the resource package ID, and then add the extended package effect. For example, the resource package here is installed in a synchronous method, if the resource package size is too large or it's based on needs, an asynchronous installation can be used. </p><pre class="fragment">        String package1Path = "assets:/7FFCF99A-5336-4464-BACD-9D32D5D2DC5E.videofx";
        m_fxPackageId = new StringBuilder();
        int error = m_streamingContext.getAssetPackageManager().installAssetPackage(package1Path, null, NvsAssetPackageManager.ASSET_PACKAGE_TYPE_VIDEOFX, true, m_fxPackageId);
        if (error != NvsAssetPackageManager.ASSET_PACKAGE_MANAGER_ERROR_NO_ERROR
                &amp;&amp; error != NvsAssetPackageManager.ASSET_PACKAGE_MANAGER_ERROR_ALREADY_INSTALLED) {
            Log.e(TAG, "Failed to install asset package!");
        }

                    //append video effect
        m_streamingContext.appendPackagedCaptureVideoFx(m_fxPackageId.toString());
</pre><h2><a class="anchor" id="Editing"></a>
3.2 Editing</h2>
<p>General steps to implement video editing:</p><ul>
<li>Initialize firstlt the class of "NvsStreamingContext".If it has already been initialized, the object can be directly obtained. <pre class="fragment">          m_streamingContext = NvsStreamingContext.getInstance();
</pre></li>
<li>Create a timeline. Users can create a timeline by the object of "NvsStreamingContext". If necessary, multiple timelines can be created in one program. Generally,the advice is that it's enough to create a timeline.</li>
<li>Add tracks, including the video track and audio tracks. Users can add both video tracks and audio tracks to the timeline. After video track is added, user can add the video clips onto the video track, and audio clips onto audio track. If user wants to implement a picture-in-picture, two video tracks are required. The audio track is generally used to adding audio or dubbing to the video track.</li>
<li>Add the video and audio clips onto the track. Multiple video clips can be added to the video track, which can be video files or pictures, and finally realize the Hybrid editing for the video and image. Multiple music files can also be added to the audio track. </li>
</ul>
<h2><a class="anchor" id="Create"></a>
the timeline and set the video resolution 3.2.1 Create the timeline and set the video resolution</h2>
<p>Creating a timeline is critical for editing. The video resolution of the timeline determines the maximum resolution (size) when compiling the video file. Please match the resolution of the timeline with the aspect ratio of NvsLiveWindow. </p><pre class="fragment">        NvsVideoResolution videoEditRes = new NvsVideoResolution();
                    videoEditRes.imageWidth = 1280; //video resolution width
                    videoEditRes.imageHeight = 720; //video resolution hight
                    videoEditRes.imagePAR = new NvsRational(1, 1); //pixel ratio, set to 1:1
                    NvsRational videoFps = new NvsRational(25, 1); //frame rate, users can set 25 or 30, generally 25.

        NvsAudioResolution audioEditRes = new NvsAudioResolution();
                    audioEditRes.sampleRate = 44100; //audio sampling rate, users can set 48000 or 44100
                    audioEditRes.channelCount = 2; //count of audio channels
</pre><p>Create a timeline: </p><pre class="fragment">        m_timeline = m_streamingContext.createTimeline(videoEditRes, videoFps, audioEditRes);
</pre><p>Connect the timeline to the NvsLiveWindow control to preview images on the timeline: </p><pre class="fragment">        m_streamingContext.connectTimelineWithLiveWindow(m_timeline,m_liveWindow);
                    m_streamingContext.setCompileCallback(this);//set the callback interface of compiling
                    m_streamingContext.setPlaybackCallback(this);//set the callback interface of playback
</pre><h2><a class="anchor" id="Hybrid"></a>
editing for the multi-segment video and image 3.2.2 Hybrid editing for the multi-segment video and image</h2>
<p>In general, create a video track and then add images or videos onto the track. The materials added to the track, we call them the clips. Both image and video clips are added to the track via the file path. Please note: If the image size is too large, you need to reduce the size of the image. The size of the reduced image had better matching the size of the resolution that creates the timeline.</p>
<p>Append video track: </p><pre class="fragment">                    m_videoTrack = m_timeline.appendVideoTrack();
</pre><p>Append audio track: </p><pre class="fragment">                    m_audioTrack = m_timeline.appendAudioTrack();
</pre><p>Append a clip: </p><pre class="fragment">                    for(int i = 0; i &lt; pathList.size(); i++) {
                            NvsVideoClip clip = m_videoTrack.appendClip(pathList.get(i));
                    }
</pre><h2><a class="anchor" id="Playback"></a>
and seeking 3.2.3 Playback and seeking</h2>
<p>For the interface of playback and seeking, the parameter of "videoSizeMode" is recommended to be set to "NvsStreamingContext.VIDEO_PREVIEW_SIZEMODE_LIVEWINDOW_SIZE". If there is no special requirement, the mode that set to "NvsStreamingContext.VIDEO_PREVIEW_SIZEMODE_FULLSIZE" will affect performance. and "preload" is preloaded and set to YES. Note: The time unit of the Meishe SDK is microseconds, 1/1000000 seconds. <br  />
Video playback, the parameter of "endTime" for playbackTimeline() can be set _timeline.duration or -1. </p><pre class="fragment">        m_streamingContext.playbackTimeline(m_timeline, m_streamingContext.getTimelineCurrentPosition(m_timeline), -1, NvsStreamingContext.VIDEO_PREVIEW_SIZEMODE_LIVEWINDOW_SIZE, true, 0);
</pre><p>Video seeking: </p><pre class="fragment">        m_streamingContext.seekTimeline(m_timeline, 0, NvsStreamingContext.VIDEO_PREVIEW_SIZEMODE_LIVEWINDOW_SIZE, 0);
</pre><h2><a class="anchor" id="Video"></a>
triming 3.2.4 Video triming</h2>
<p>Change the in and point points of the clip so that trim the clip. </p><pre class="fragment">        NvsVideoClip clip = m_videoTrack.getClipByIndex(m_currentPosition);
        clip.changeTrimInPoint((long)trim_in, true);
        clip.changeTrimOutPoint((long)trim_out, true);
</pre><h2><a class="anchor" id="Remove"></a>
the clip on the track 3.2.5 Remove the clip on the track</h2>
<p>Remove the clip: </p><pre class="fragment">        m_videoTrack.removeClip(0, false);
</pre><h2><a class="anchor" id="Sorting"></a>
of the video clip 3.2.6 Sorting of the video clip</h2>
<p>The clips on the track can be interchanged, and the parameters of "clipIndex" and "destClipIndex" for moveClip() represent the index of the two materials that are interchanged, respectively. </p><pre class="fragment">        m_videoTrack.moveClip(0,3);
</pre><h2><a class="anchor" id="Define"></a>
the duration for image 3.2.7 Define the duration for image</h2>
<p>The NvsVideoTrack class provides appendClip(String filePath, long trimIn, long trimOut) that You can freely set the duration of the image on the track as needed. the parameter of "filePath" for appendClip:trimIn:trimOut: is the path of the picture material, "trimIn" is set to 0, and "trimOut" is set to 8000000,the result is that the picture display as 8 seconds. </p><pre class="fragment">                    m_videoTrack.appendClip(pathList.get(i),0,8000000);
</pre><p>If the image is added by appendClip(String filePath), the default display time of the image is 4 seconds. </p>
<h2><a class="anchor" id="Remove"></a>
the clip on the track 3.2.5 Remove the clip on the track</h2>
<p>The created timeline, the added video track and audio track are removed if they are no longer needed. The operation is as follows: <br  />
Remove the timeline： </p><pre class="fragment">        m_streamingContext.removeTimeline(m_timeline);
</pre><p>Remove the video track: </p><pre class="fragment">        m_timeline.removeVideoTrack(0);
</pre><p>Remove the audio track: </p><pre class="fragment">        m_timeline.removeAudioTrack(0);
</pre> <h2><a class="anchor" id="Audio"></a>
implementation 3.3 Audio implementation</h2>
<h2><a class="anchor" id="Add"></a>
Add</h2>
<p>Adding music to a video is done by adding audio clips onto the audio track. Once the timeline is created, add an audio track via "appendAudioTrack" and add the music file as an audio clip to the audio track. You can add multiple pieces of music and the music will play continuously. </p><pre class="fragment">                    //add an audio track
                    m_audioTrack = m_timeline.appendAudioTrack();
        m_audioTrack.appendClip(pathList.get(i));
</pre><h2><a class="anchor" id="Music"></a>
triming 3.3.2 Music triming</h2>
<p>Music triming is the same as video triming, and it's also trimed by setting the in and out points. </p><pre class="fragment">        NvsAudioClip clip = m_audioTrack.getClipByIndex(m_currentPosition);
        clip.changeTrimInPoint((long)trim_in, true);
        clip.changeTrimOutPoint((long)trim_out, true);  
</pre><h2><a class="anchor" id="Caption"></a>
Caption</h2>
<p>Adding, deleting, and getting captions are all performed on the timeline. You can refer to the caption editing module of the SdkDemo example. </p>
<h2><a class="anchor" id="Add"></a>
Add</h2>
<p>Add the caption and set the duration of the caption which display. </p><pre class="fragment">                     NvsTimelineCaption m_timelineCapion = m_timeline.addCaption("Meishe SDK", 0, m_timeline.getDuration(), null);
</pre><p>Remove the caption and return the next caption object on the timeline. Returns nil if there is no next caption. </p><pre class="fragment">         NvsTimelineCaption nextCaption = m_timeline.removeCaption(m_timelineCapion);
</pre><h2><a class="anchor" id="Get"></a>
the caption from timeline 3.4.2 Get the caption from timeline</h2>
<p>There are several ways to get captions: </p><pre class="fragment">                    //Get the first caption on the timeline
                    NvsTimelineCaption firstCaption = m_timeline.getFirstCaption();

                    //Get the last caption on the timeline
                    NvsTimelineCaption lastCaption = m_timeline.getLastCaption();

                    //Get the previous caption of the current caption on the timeline
                    NvsTimelineCaption prevCaption = m_timeline.getPrevCaption(currentCaption);

                    //Get the next caption of the current caption on the timeline
                    NvsTimelineCaption lastCaption = m_timeline.getNextCaption(currentCaption);
</pre><p>Get The captions according to the position on the timeline, and the List collection of the captions of the current position is returned. The sorting rules for the obtained caption list are as follows: <br  />
1.When adding, if the in points of captions are different, they are arranged in the order of the in points; <br  />
2.When adding, if the in points of captions are the same, they are arranged in the order of adding captions. </p><pre class="fragment">                    List&lt;NvsTimelineCaption&gt; cpationList = m_timeline.getCaptionsByTimelinePosition(1000000);
</pre><h2><a class="anchor" id="Modify"></a>
properties of caption 3.4.3 Modify properties of caption</h2>
<p>Modifying the caption properties can be done by the methods of NvsTimelineCaption class. After getting captions, you can set the caption text, color, bold, italic, stroke, etc. <br  />
Take the example of modifying the caption text: </p><pre class="fragment">                    currentCaption.setText("Meishe SDK");
</pre><p>If it's a panorama caption, you can also set the polar angle of the caption center point, the azimuth of the caption center point, and so on. Take the polar angle of the center point of the caption as an example: </p><pre class="fragment">                    currentCaption.setCenterPolarAngle(1.2);
</pre><h2><a class="anchor" id="Modify"></a>
properties of caption 3.4.3 Modify properties of caption</h2>
<p>After captions are acquired, you can modify the in points, out points, and offset values of the captions on the timeline.</p>
<pre class="fragment">                    //change the in point
                    currentCaption.changeInPoint(1000000);

                    //change the out point
                    currentCaption.changeOutPoint(5000000);

                    //Change the display position (the in and out points move the value of "offset" at the same time)
                    currentCaption.movePosition(1000000);
</pre><h2><a class="anchor" id="Animated"></a>
sticker 3.5 Animated sticker</h2>
<p>Adding, deleting, and getting animated stickers are also performed on the timeline. See the sticker module of "SdkDemo" demo. </p>
<h2><a class="anchor" id="Add"></a>
Add</h2>
<p>Add an animated sticker: </p><pre class="fragment">        m_timeline.addAnimatedSticker(0, m_timeline.getDuration(), m_stickerId.toString());
</pre><p>Remove the animated sticker and return to the next sticker of the current sticker. If there is no next sticker, return null. </p><pre class="fragment">                    NvsTimelineAnimatedSticker nextSticker = m_timeline.removeAnimatedSticker(currentSticker);
</pre><h2><a class="anchor" id="Get"></a>
the caption from timeline 3.4.2 Get the caption from timeline</h2>
<p>There are several ways to get the animated stickers which added on the timeline. </p><pre class="fragment">                    //Get the first animated sticker on the timeline
                    NvsTimelineAnimatedSticker firstSticker = m_timeline.getFirstAnimatedSticker();
                    //Get the last animated sticker on the timeline
                    NvsTimelineAnimatedSticker lastSticker = m_timeline.getLastAnimatedSticker();
                    //Get the previous animated sticker of the current animated sticker on the timeline
                    NvsTimelineAnimatedSticker prevSticker = m_timeline.getPrevAnimatedSticker(currentSticker);
                    //Get the next animated sticker of the current animated sticker on the timeline
                    NvsTimelineAnimatedSticker nextSticker = m_timeline.getNextAnimatedSticker(currentSticker);
</pre><p>Get the animated stickers based on the position on the timeline and return the List collection that holds animated sticker object in the current position. The sorting rules for the obtained animated sticker list are as follows: <br  />
1.When adding, the in points are different,the animated stickers are arranged in the order of the in points; <br  />
2.When adding, the in points are the same, the animation stickers are arranged in the order which added. </p><pre class="fragment">                    List&lt;NvsTimelineAnimatedSticker&gt; stickerList = m_timeline.getAnimatedStickersByTimelinePosition(1000000);
</pre><h2><a class="anchor" id="Modify"></a>
properties of caption 3.4.3 Modify properties of caption</h2>
<p>Modifying the sticker properties can be done by the method of NvsTimelineAnimatedSticker class. After getting the sticker, you can set the zoom value, horizontal flip, rotation angle, translation and so on. <br  />
Take the modified sticker scale as an example: </p><pre class="fragment">                    currentSticker.setScale(1.2);
</pre><p>If it's a panorama animation sticker, you can also set the polar angle of the center point for the sticker, the azimuth angle of the center point for the sticker, and so on. Take the polar angle of the center point as an example: </p><pre class="fragment">                    currentSticker.setCenterPolarAngle(1.2);
</pre><h2><a class="anchor" id="Modify"></a>
properties of caption 3.4.3 Modify properties of caption</h2>
<p>After getting the sticker, you can modify the in point, out point and offset value of the animated sticker on the timeline. </p><pre class="fragment">                    //Change in point
                    [currentSticker changeInPoint:1000000];
                    //Change out point
                    [currentSticker changeOutPoint:5000000];
                    //Change the display position (in and out points move the value of "offset" at the same time)
                    [currentSticker movePosition:1000000];
</pre><h2><a class="anchor" id="Theme"></a>
Theme</h2>
<p>When editing a video, if you need to apply a theme, you can add and remove it through the timeline. </p>
<h2><a class="anchor" id="Add"></a>
Add</h2>
<p>Apply a theme: m_timeline.applyTheme(m_themeId.toString());</p>
<p>Remove the current theme： </p><pre class="fragment">        m_timeline.removeCurrentTheme();
</pre><h2><a class="anchor" id="Get"></a>
the caption from timeline 3.4.2 Get the caption from timeline</h2>
<p>Get the package Id of current theme: </p><pre class="fragment">        m_timeline.getCurrentThemeId();
</pre><h2><a class="anchor" id="Modify"></a>
properties of caption 3.4.3 Modify properties of caption</h2>
<p>After applying the theme, you can set the theme title, trailer, theme music volume, etc. Take to set the theme title as an example: </p><pre class="fragment">                    m_timeline.setThemeTitleCaptionText("Meishe SDK");
</pre><h2><a class="anchor" id="Transition"></a>
3.7 Transition</h2>
<p>Transitions include video transitions and audio transitions. Video transitions are set on the video track, and audio transitions are set on the audio track. <br  />
Video transitions include built-in transitions and package transitions. Here,set the video built-in transitions: </p><pre class="fragment">                    m_videoTrack.setBuiltinTransition(0,transitionName);
</pre><p>Video package transition: </p><pre class="fragment">                    m_videoTrack.setPackagedTransition(1，m_transitionId.toString());
</pre><p>Similarly, the audio transition is the same usage as the video transition, and the user can refer to it. </p>
<h2><a class="anchor" id="Special"></a>
effects with recording 3.1.9 Special effects with recording</h2>
<p>In video follow-up editing, several effects are often used, namely video effects (NvsVideoFx), audio effects (NvsAudioFx), and timeline video effects (NvsTimelineVideoFx). </p>
<h2><a class="anchor" id="Video"></a>
triming 3.2.4 Video triming</h2>
<p>Video effects are used on video clips, and each video clip can add several video effects. Video effects include built-in video effects, package video effects, and beauty effects. <br  />
Add a built-in video effect: </p><pre class="fragment">        videoClip.appendBuiltinFx(fxName);
</pre><p>Add a package video effect: </p><pre class="fragment">        videoClip.appendPackagedFx(m_fxPackageId.toString());//添加包裹特效    
</pre><p>Add a beauty video effect: </p><pre class="fragment">        videoClip.appendBeautyFx();
</pre><p>Removing the video effect includes removing the specified index of effect and removing all video effects. <br  />
Remove the specified index of vedio effect: </p><pre class="fragment">        videoClip.removeFx(0);
</pre><p>Remove all video effects: </p><pre class="fragment">        videoClip.removeAllFx();
</pre><h2><a class="anchor" id="Audio"></a>
implementation 3.3 Audio implementation</h2>
<p>Audio effects are used on audio clips, and each audio clip can add several audio effects. <br  />
Add an audio effect: </p><pre class="fragment">        audioClip.appendFx(fxName);
</pre><p>Remove the specified index of audio effects: </p><pre class="fragment">        audioClip.removeFx(0);
</pre><h2><a class="anchor" id="Timeline"></a>
Timeline</h2>
<p>Timeline video effects are an effect that is used on the timeline, including built-in effects and package effects. Several timeline video effects can be added to the timeline. </p>
<h2><a class="anchor" id="Add"></a>
Add</h2>
<p>Add timeline effects: </p><pre class="fragment">                    m_timeline.addBuiltinTimelineVideoFx(1000000,5000000,fxName);
                    m_timeline.addPackagedTimelineVideoFx(1000000,5000000,fxPackageId);
</pre><h2><a class="anchor" id="Get"></a>
the caption from timeline 3.4.2 Get the caption from timeline</h2>
<p>There are several ways to get timeline effects. </p><pre class="fragment">                    //Get the first timeline video effect on the timeline
                    NvsTimelineVideoFx firstTimelineFx = m_timeline.getFirstTimelineVideoFx();
                    //Get the last timeline video effect on the timeline
                    NvsTimelineVideoFx lastTimelineFx = m_timeline.getLastTimelineVideoFx();
                    //Get the previous timeline video effect of the current timeline video effect on the timeline
                    NvsTimelineVideoFx prevTimelineFx = m_timeline.getPrevTimelineVideoFx(currentTimelineFx);
                    //Get the next timeline video effect of the current timeline video effect on the timeline
                     NvsTimelineVideoFx nextTimelineFx = m_timeline.getNextTimelineVideoFx(currentTimelineFx);
</pre><p>Gets the timeline video effects based on the position on the timeline, returning an array of video effects objects in current position of timeline. The ordering rules for the obtained timeline video effects array are as follows: <br  />
1.When adding, the in points of the timeline video effects are different, they are arranged in the order of the in points; <br  />
2.When adding, the in points of the timeline video effects are the same, they are arranged in the order of adding timeline video effects.</p>
<pre class="fragment">                    List&lt;NvsTimelineVideoFx&gt; timelineFxArray = m_timeline.getTimelineVideoFxByTimelinePosition(2000000);
</pre><h2><a class="anchor" id="Modify"></a>
properties of caption 3.4.3 Modify properties of caption</h2>
<p>After you get the timeline effects, you can modify the in points, out points, and offset values of the timeline effects on the timeline. </p><pre class="fragment">                    //Change in point
                    currentTimelineFx.changeInPoint(1000000);
                    //Change out point
                    currentTimelineFx.changeOutPoint(5000000);
                    //Change the display position (in and out points move the value of "offset" at the same time)
                    currentTimelineFx.movePosition(1000000);
</pre><h2><a class="anchor" id="Compiling"></a>
3.9 Compiling</h2>
<p>The Meishe SDK uses compileTimeline:startTime:endTime:outputFilePath:videoResolutionGrade:videoBitrateGrade:flags: to compile a new video from the clip on the timeline. <br  />
Compiling video： </p><pre class="fragment">        m_streamingContext.compileTimeline(m_timeline, 0, m_timeline.getDuration(),
            m_compilePath, NvsStreamingContext.COMPILE_VIDEO_RESOLUTION_GRADE_720, NvsStreamingContext.COMPILE_BITRATE_GRADE_HIGH, 0);
</pre><h2><a class="anchor" id="Asset"></a>
package management 3.10 Asset package management</h2>
<p>The Meihshe SDK provides a rich library of Assets, including animated stickers, themes, caption styles, transitions, and more. The package can be downloaded from the web or provided by the Meishe SDK project team, and users can choose to use these packages as needed. The Meishe SDK manages these Asset packages through the NvsAssetPackageManager class, which can installe, upgrade, uninstalle, obtaine the status of the material package, version number, and so on. <br  />
Package installation: </p><pre class="fragment">                    //Synchronous installation is used here, if the package is too large, asynchronous mode can be
        int error = m_streamingContext.getAssetPackageManager().installAssetPackage(stickerPackagePath, null, NvsAssetPackageManager.ASSET_PACKAGE_TYPE_ANIMATEDSTICKER, true, m_stickerId);
</pre><p>Package upgrade: </p><pre class="fragment">                    //Synchronous installation is used here, if the package is too large, asynchronous mode can be used.
        int error = m_streamingContext.getAssetPackageManager().upgradeAssetPackage(stickerPackagePath, null, NvsAssetPackageManager.ASSET_PACKAGE_TYPE_ANIMATEDSTICKER, true, m_stickerId);
</pre><p>Package uninstallation: </p><pre class="fragment">        int error = m_streamingContext.getAssetPackageManager().uninstallAssetPackage(m_stickerId,NvsAssetPackageManager.ASSET_PACKAGE_TYPE_ANIMATEDSTICKER);
</pre><h2><a class="anchor" id="Callback"></a>
3.11 Callback</h2>
<p>The Meihse SDK provides a lot of delegate interfaces. If you want to query the status of the captured device, the recording status, video playback status, file compilation status, resource package installation status, etc., you must set the delegate and implement the corresponding delegate interface after creating the NvsStreamingContext object. <br  />
Take the video playback callback as an example: </p><pre class="fragment">        m_streamingContext.setPlaybackCallback(this);
</pre><h2><a class="anchor" id="Appendix"></a>
4 Appendix</h2>
<p>The Meishe SDK version includes the speed version, the standard function version, and the full-featured PRO version. For the function points of each version, please refer to: <a href="https://www.meishesdk.com/editsdk">https://www.meishesdk.com/editsdk</a>, there will be a detailed introduction. Each user can choose to use according to their individual needs and please contact us for details. </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.17
</small></address>
</body>
</html>
